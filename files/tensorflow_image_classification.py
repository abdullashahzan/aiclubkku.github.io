# -*- coding: utf-8 -*-
"""TensorFlow-image-classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VZwg9xB05d7iSn913TqjdgqfJPBopsva

# **Downloading and unzipping the dataset**
"""

!wget https://bitbucket.org/ishaanjav/code-and-deploy-custom-tensorflow-lite-model/raw/a4febbfee178324b2083e322cdead7465d6fdf95/fruits.zip

!unzip fruits.zip

"""# **Importing required libraries**"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

"""# **Splitting the training, testing and validatinng data**"""

train_ds = tf.keras.utils.image_dataset_from_directory(
    "fruits/train",
    image_size=(32,32),
    batch_size=20
)
val_ds = tf.keras.utils.image_dataset_from_directory(
    "fruits/validation",
    image_size=(32,32),
    batch_size=20
)
test_ds = tf.keras.utils.image_dataset_from_directory(
    "fruits/test",
    image_size=(32,32),
    batch_size=20
)

#Training data is used to train the neural network and the validation data is used to check its score (accuracy) whereas
#testing data is the one where we test our neural network.

"""# **Looking at our data**"""

class_names = ["apple", "banana", "orange"]
for images, labels in train_ds.take(1):
  for i in range(5):
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.show()

"""# **Building the layers of our neural network**"""

model = tf.keras.Sequential(
    [
     tf.keras.layers.Rescaling(1./255),

     tf.keras.layers.Conv2D(32, 3, activation="relu"),
     tf.keras.layers.MaxPooling2D(),

     tf.keras.layers.Conv2D(32, 3, activation="relu"),
     tf.keras.layers.MaxPooling2D(),

     tf.keras.layers.Conv2D(32, 3, activation="relu"),
     tf.keras.layers.MaxPooling2D(),

     tf.keras.layers.Flatten(),
     tf.keras.layers.Dense(128, activation="relu"),
     tf.keras.layers.Dense(3)
    ]
)

#Convolutional layer (Conv2D) applies filters to the image so we can gather data from it 
#We applie 32 filters and kept the kernel size to 3 by 3.
#Maxpooling layer down samples the size of feature maps making it easier for our neural network to understand
#Flatten layer turns the matrix into one dimensional array

"""# **Compiling our neural network**"""

model.compile(
    optimizer="adam",
    loss=tf.losses.SparseCategoricalCrossentropy(from_logits = True),
    metrics=['accuracy']
)

"""# **Fitting data and training our neural network**"""

model.fit(
    train_ds,
    validation_data = val_ds,
    epochs = 10
)

"""# **Evaluating our neural network**"""

model.evaluate(test_ds)

"""# **Testing our neural network**"""

import numpy

plt.figure(figsize=(10,10))
for images, labels in test_ds.take(1):
  # Predicts our test image
  classifications = model(images)
  
  for i in range(9):
    ax = plt.subplot(4, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))

    #Returns the highest value
    index = numpy.argmax(classifications[i])
    plt.title("Pred: " + class_names[index] + " | Real: " + class_names[labels[i]])